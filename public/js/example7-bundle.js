/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
/******/ (() => { // webpackBootstrap
/******/ 	"use strict";
/******/ 	var __webpack_modules__ = ({

/***/ "./build/TinyShade.js":
/*!****************************!*\
  !*** ./build/TinyShade.js ***!
  \****************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.TinyShade = void 0;\nconst UniformLayout_1 = __webpack_require__(/*! ./UniformLayout */ \"./build/UniformLayout.js\");\nconst Buffer = {\n    write(device, buffer, data, offset = 0) {\n        device.queue.writeBuffer(buffer, offset, data.buffer, data.byteOffset, data.byteLength);\n        return buffer;\n    }\n};\nconst largestPowerOf2LessThan = (n) => {\n    let power = 1;\n    while (power * 2 <= n)\n        power *= 2;\n    return power;\n};\nconst getWorkgroupSize = (limits) => {\n    const x = Math.min(16, largestPowerOf2LessThan(limits.maxComputeWorkgroupSizeX));\n    const y = Math.min(16, largestPowerOf2LessThan(limits.maxComputeWorkgroupSizeY));\n    return { x, y, z: 1, str: `@workgroup_size(${x}, ${y}, 1)` };\n};\n/**\n * TinyShade - A WebGPU-based shader rendering framework\n *\n * A flexible shader renderer that supports multiple render passes, compute shaders,\n * textures, and audio synchronization. Provides a fluent API for composing complex\n * GPU pipelines with automatic uniform management and bind group generation.\n *\n * @example\n * ```typescript\n * const shade = await TinyShade.create('canvas-id');\n *\n * shade\n *   .addTexture('myTexture', 'path/to/image.png')\n *   .setUniforms((layout) => layout.setUniform('myUniform', 1.0))\n *   .addCommon('fn myHelper() { ... }')\n *   .addCompute('computePass', 'compute shader code')\n *   .addPass('renderPass', 'fragment shader code')\n *   .main('main fragment shader')\n *   .run();\n * ```\n *\n * @class TinyShade\n * @property {GPUDevice} device - The WebGPU device instance\n * @property {number} frameCounter - Current frame number\n */\nclass TinyShade {\n    device;\n    context;\n    canvas;\n    uniforms;\n    uniformBuffer;\n    audioPlugin;\n    startTime = 0;\n    frameCounter = 0;\n    globalTextures = new Map();\n    commonWGSL = \"\";\n    passes = [];\n    passLayouts = [];\n    mainPassShader = \"\";\n    mainPipeline;\n    isCompiled = false;\n    startedAudio = false;\n    workgroupSize = { x: 8, y: 8, z: 1, str: \"@workgroup_size(8, 8, 1)\" };\n    constructor(canvas) {\n        this.canvas = canvas;\n        this.uniforms = new UniformLayout_1.UniformLayout([this.canvas.width, this.canvas.height, window.devicePixelRatio]);\n    }\n    /**\n     * Creates and initializes a new TinyShade instance with WebGPU support.\n     * @param canvasId - The HTML element ID of the canvas to bind to the renderer\n     * @returns A promise that resolves to an initialized TinyShade instance\n     * @throws If the canvas element with the specified ID is not found\n     * @throws If WebGPU initialization fails\n     */\n    static async create(canvasId) {\n        const canvas = document.getElementById(canvasId);\n        const ts = new TinyShade(canvas);\n        await ts.initWebGPU();\n        return ts;\n    }\n    async initWebGPU() {\n        const adapter = await navigator.gpu?.requestAdapter();\n        if (!adapter)\n            throw \"WebGPU not supported\";\n        const features = [];\n        if (adapter.features.has('bgra8unorm-storage'))\n            features.push('bgra8unorm-storage');\n        if (adapter.features.has('timestamp-query'))\n            features.push('timestamp-query');\n        this.device = await adapter.requestDevice({ requiredFeatures: features });\n        this.workgroupSize = getWorkgroupSize(adapter.limits);\n        this.context = this.canvas.getContext(\"webgpu\");\n        this.context.configure({\n            device: this.device,\n            format: navigator.gpu.getPreferredCanvasFormat(),\n            usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.STORAGE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT\n        });\n        this.startTime = performance.now();\n    }\n    /**\n     * Adds an audio plugin to the shader instance.\n     * @param plugin - The audio plugin to be added.\n     * @returns The current instance for method chaining.\n     */\n    addAudio(plugin) {\n        this.audioPlugin = plugin;\n        console.log(this.audioPlugin);\n        return this;\n    }\n    /**\n     * Adds common WGSL code to the shader.\n     * @param wgsl - The WGSL code string to add to the common section.\n     * @returns The current instance for method chaining.\n     */\n    addCommon(wgsl) {\n        this.commonWGSL += `\\n${wgsl}\\n`;\n        return this;\n    }\n    /**\n     * Adds a texture to the shader with the specified name.\n     * @param name - The name to associate with the texture\n     * @param src - The texture source, either a URL string, HTMLImageElement, or HTMLCanvasElement\n     * @returns A promise that resolves to this instance for method chaining\n     * @throws Will throw if the image fails to load or decode\n     */\n    async addTexture(name, src) {\n        let source;\n        if (typeof src === 'string') {\n            const img = new Image();\n            img.src = src;\n            await img.decode();\n            source = await createImageBitmap(img);\n        }\n        else {\n            source = src;\n        }\n        const texture = this.device.createTexture({\n            size: [source.width, source.height],\n            format: 'rgba8unorm',\n            usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.COPY_DST | GPUTextureUsage.RENDER_ATTACHMENT\n        });\n        this.device.queue.copyExternalImageToTexture({ source }, { texture }, [source.width, source.height]);\n        this.globalTextures.set(name, texture);\n        return this;\n    }\n    /**\n     * Sets up the uniform buffer and optionally applies a callback to the uniform layout.\n     * @param callback - Optional callback function that receives the uniform layout for configuration.\n     * @returns The current instance for method chaining.\n     */\n    setUniforms(callback) {\n        if (callback)\n            callback(this.uniforms);\n        this.uniformBuffer = this.device.createBuffer({\n            size: this.uniforms.byteSize,\n            usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST\n        });\n        return this;\n    }\n    /**\n     * Adds a compute shader pass to the rendering pipeline.\n     * @param name - The name identifier for this compute pass.\n     * @param wgsl - The WGSL shader code to execute.\n     * @param size - Optional size of the storage buffer in units (default: 0). If greater than 0, a storage buffer of size * 4 bytes will be created.\n     * @returns The current instance for method chaining.\n     */\n    addCompute(name, wgsl, size = 0) {\n        const tex = this.device.createTexture({\n            size: [this.canvas.width, this.canvas.height],\n            format: \"rgba8unorm\",\n            usage: GPUTextureUsage.STORAGE_BINDING | GPUTextureUsage.TEXTURE_BINDING\n        });\n        let buf;\n        if (size > 0)\n            buf = this.device.createBuffer({ size: size * 4, usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST });\n        this.passes.push({ name: name, type: 'compute', shader: wgsl, textures: [tex], storageBuffer: buf, pipelines: [] });\n        return this;\n    }\n    /**\n     * Adds an atomic compute shader pass to the renderer.\n     * @param name - The name identifier for this compute pass\n     * @param wgsl - The WGSL shader code for the compute shader\n     * @param bufferSize - The number of u32 elements in the storage buffer\n     * @returns This instance for method chaining\n     */\n    addAtomicCompute(name, wgsl, bufferSize) {\n        const buf = this.device.createBuffer({\n            size: bufferSize * 4, // 4 bytes for u32\n            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC | GPUBufferUsage.COPY_DST\n        });\n        this.passes.push({\n            name,\n            type: 'compute',\n            shader: wgsl,\n            storageBuffer: buf,\n            isAtomic: true,\n            pipelines: [],\n            textures: []\n        });\n        return this;\n    }\n    /**\n     * Adds a render pass to the shader pipeline.\n     * @param name - The name identifier for the pass\n     * @param wgsl - The WGSL shader code for the fragment stage\n     * @returns The current instance for method chaining\n     */\n    addPass(name, wgsl) {\n        const createTex = () => this.device.createTexture({\n            size: [this.canvas.width, this.canvas.height],\n            format: \"bgra8unorm\",\n            usage: GPUTextureUsage.TEXTURE_BINDING | GPUTextureUsage.RENDER_ATTACHMENT\n        });\n        this.passes.push({ name: name, type: 'fragment', shader: wgsl, textures: [createTex(), createTex()], pipelines: [] });\n        return this;\n    }\n    /**\n     * Sets the main pass shader and compiles it.\n     * @param wgsl - The WGSL shader code to set as the main pass shader.\n     * @returns A promise that resolves to this instance for method chaining.\n     */\n    async main(wgsl) {\n        this.mainPassShader = wgsl;\n        this.compile();\n        return this;\n    }\n    compile() {\n        if (!this.uniformBuffer)\n            this.setUniforms();\n        const vertCode = `\r\n        struct VSOut { @builtin(position) pos: vec4f, @location(0) uv: vec2f };\r\n        @vertex fn vs(@builtin(vertex_index) i: u32) -> VSOut {\r\n            var p = array<vec2f, 3>(vec2f(-1.0, -1.0), vec2f(3.0, -1.0), vec2f(-1.0, 3.0));\r\n            return VSOut(vec4f(p[i], 0.0, 1.0), vec2f(p[i].x * 0.5 + 0.5, 0.5 - p[i].y * 0.5));\r\n        }\r\n    `;\n        const allStages = [...this.passes, {\n                name: \"main\",\n                type: 'fragment',\n                shader: this.mainPassShader,\n                isMain: true,\n                textures: [],\n                pipelines: []\n            }];\n        allStages.forEach((currentPass, stageIdx) => {\n            let b = 1; // Binding 0 is always Uniforms\n            const layoutEntries = [{\n                    binding: 0,\n                    visibility: GPUShaderStage.VERTEX | GPUShaderStage.FRAGMENT | GPUShaderStage.COMPUTE,\n                    buffer: { type: 'uniform' }\n                }];\n            let header = `${this.uniforms.wgslStruct}\\n@group(0) @binding(0) var<uniform> u: Uniforms;\\n`;\n            // Global Textures\n            this.globalTextures.forEach((_, name) => {\n                header += `@group(0) @binding(${b}) var ${name}: texture_2d<f32>;\\n`;\n                layoutEntries.push({ binding: b++, visibility: GPUShaderStage.FRAGMENT | GPUShaderStage.COMPUTE, texture: {} });\n            });\n            // Global Sampler\n            header += `@group(0) @binding(${b}) var samp: sampler;\\n`;\n            layoutEntries.push({ binding: b++, visibility: GPUShaderStage.FRAGMENT | GPUShaderStage.COMPUTE, sampler: {} });\n            // Pass-specific Resources\n            this.passes.forEach((p) => {\n                if (p.type === 'compute') {\n                    // 1. Storage Textures (Only if the pass has one)\n                    if (p.textures.length > 0) {\n                        if (currentPass === p) {\n                            header += `@group(0) @binding(${b}) var outTex: texture_storage_2d<rgba8unorm, write>;\\n`;\n                            layoutEntries.push({ binding: b++, visibility: GPUShaderStage.COMPUTE, storageTexture: { format: 'rgba8unorm', access: 'write-only' } });\n                        }\n                        else {\n                            header += `@group(0) @binding(${b}) var ${p.name}: texture_2d<f32>;\\n`;\n                            layoutEntries.push({ binding: b++, visibility: GPUShaderStage.FRAGMENT | GPUShaderStage.COMPUTE, texture: {} });\n                        }\n                    }\n                    // 2. Storage Buffers (Atomic or Standard)\n                    if (p.storageBuffer) {\n                        const isOwner = (currentPass === p);\n                        const arrayType = p.isAtomic ? \"array<atomic<u32>>\" : \"array<f32>\";\n                        const bufName = isOwner ? \"data\" : `${p.name}_data`;\n                        header += `@group(0) @binding(${b}) var<storage, read_write> ${bufName}: ${arrayType};\\n`;\n                        layoutEntries.push({\n                            binding: b++,\n                            visibility: GPUShaderStage.COMPUTE | GPUShaderStage.FRAGMENT,\n                            buffer: { type: 'storage' }\n                        });\n                    }\n                }\n                else {\n                    // Fragment Pass Textures (Ping-Pong)\n                    header += `@group(0) @binding(${b}) var ${p.name}: texture_2d<f32>;\\n`;\n                    layoutEntries.push({ binding: b++, visibility: GPUShaderStage.FRAGMENT | GPUShaderStage.COMPUTE, texture: {} });\n                    header += `@group(0) @binding(${b}) var prev_${p.name}: texture_2d<f32>;\\n`;\n                    layoutEntries.push({ binding: b++, visibility: GPUShaderStage.FRAGMENT | GPUShaderStage.COMPUTE, texture: {} });\n                }\n            });\n            const layout = this.device.createBindGroupLayout({ entries: layoutEntries });\n            this.passLayouts[stageIdx] = layout;\n            const code = (currentPass.type === 'fragment' ? vertCode : \"\") +\n                header +\n                this.commonWGSL +\n                (currentPass.type === 'compute'\n                    ? currentPass.shader.replace(\"##WORKGROUP_SIZE\", `@compute ${this.workgroupSize.str}`)\n                    : currentPass.shader);\n            const mod = this.device.createShaderModule({ code });\n            const pipeLayout = this.device.createPipelineLayout({ bindGroupLayouts: [layout] });\n            if (currentPass.type === 'compute') {\n                currentPass.pipelines[0] = this.device.createComputePipeline({\n                    layout: pipeLayout,\n                    compute: { module: mod, entryPoint: 'main' }\n                });\n            }\n            else {\n                currentPass.pipelines[0] = this.device.createRenderPipeline({\n                    layout: pipeLayout,\n                    vertex: { module: mod, entryPoint: 'vs' },\n                    fragment: {\n                        module: mod,\n                        entryPoint: 'main',\n                        targets: [{ format: currentPass.isMain ? navigator.gpu.getPreferredCanvasFormat() : \"bgra8unorm\" }]\n                    }\n                });\n                if (currentPass.isMain)\n                    this.mainPipeline = currentPass.pipelines[0];\n            }\n        });\n        this.isCompiled = true;\n    }\n    createBindGroup(stageIdx, writeIdx) {\n        const readIdx = 1 - writeIdx;\n        const entries = [{ binding: 0, resource: { buffer: this.uniformBuffer } }];\n        let b = 1;\n        // Global Textures\n        this.globalTextures.forEach(tex => entries.push({ binding: b++, resource: tex.createView() }));\n        // Global Sampler\n        entries.push({\n            binding: b++,\n            resource: this.device.createSampler({ magFilter: 'linear', minFilter: 'linear' })\n        });\n        // Pass-specific Resources\n        this.passes.forEach((p, i) => {\n            if (p.type === 'compute') {\n                // 1. Texture View\n                if (p.textures.length > 0) {\n                    // If it's a storage texture being written to, use standard view. \n                    // WebGPU automatically handles the usage based on the Layout.\n                    entries.push({ binding: b++, resource: p.textures[0].createView() });\n                }\n                // 2. Storage Buffer\n                if (p.storageBuffer) {\n                    entries.push({ binding: b++, resource: { buffer: p.storageBuffer } });\n                }\n            }\n            else {\n                // Fragment Pass Ping-Pong views\n                if (i === stageIdx) {\n                    // Currently writing to writeIdx, so we read from readIdx\n                    entries.push({ binding: b++, resource: p.textures[readIdx].createView() });\n                    entries.push({ binding: b++, resource: p.textures[readIdx].createView() });\n                }\n                else {\n                    // For other stages, just provide the most recent complete data\n                    entries.push({ binding: b++, resource: p.textures[writeIdx].createView() });\n                    entries.push({ binding: b++, resource: p.textures[readIdx].createView() });\n                }\n            }\n        });\n        return this.device.createBindGroup({ layout: this.passLayouts[stageIdx], entries });\n    }\n    /**\n     * Starts the rendering loop and begins frame rendering.\n     *\n     * @param timer - Optional WebGPU timing utility for performance measurement of render passes\n     * @returns Returns `this` for method chaining\n     *\n     * @remarks\n     * This method initiates a continuous animation loop using `requestAnimationFrame`.\n     * For each frame, it:\n     * - Manages audio plugin playback if available\n     * - Updates uniforms based on elapsed time or audio time\n     * - Executes all render/compute passes with optional timing queries\n     * - Renders the final output to the canvas\n     * - Submits all commands to the GPU queue\n     *\n     * The method alternates between two texture buffers using a ping-pong pattern\n     * to allow passes to read from and write to textures without conflicts.\n     *\n     * @example\n     * ```typescript\n     * const shader = new TinyShade();\n     * shader.compile();\n     * const timer = new WebGPUTiming(device);\n     * shader.run(timer);\n     * ```\n     */\n    run(timer) {\n        const frame = (now) => {\n            if (!this.isCompiled)\n                return;\n            if (this.audioPlugin && !this.startedAudio) {\n                this.audioPlugin.play();\n                this.startedAudio = true;\n            }\n            const useAudioTime = this.audioPlugin && this.audioPlugin.isPlaying;\n            const time = useAudioTime\n                ? this.audioPlugin.getTime()\n                : (now - this.startTime) / 1000;\n            const writeIdx = (this.frameCounter % 2);\n            this.uniforms.update(time);\n            Buffer.write(this.device, this.uniformBuffer, this.uniforms.float32Array);\n            const enc = this.device.createCommandEncoder();\n            const passTimings = [];\n            if (timer)\n                timer.reset();\n            this.passes.forEach((p, i) => {\n                if (p.isAtomic && p.storageBuffer) {\n                    enc.clearBuffer(p.storageBuffer);\n                }\n                const bg = this.createBindGroup(i, writeIdx);\n                let tw;\n                if (timer) {\n                    const idx = timer.allocateIndices();\n                    if (idx) {\n                        tw = {\n                            querySet: timer.querySet,\n                            beginningOfPassWriteIndex: idx.start,\n                            endOfPassWriteIndex: idx.end\n                        };\n                        passTimings.push({ name: p.name, ...idx });\n                    }\n                }\n                if (p.type === 'compute') {\n                    const cp = enc.beginComputePass({ timestampWrites: tw });\n                    cp.setPipeline(p.pipelines[0]);\n                    cp.setBindGroup(0, bg);\n                    cp.dispatchWorkgroups(Math.ceil(this.canvas.width / this.workgroupSize.x), Math.ceil(this.canvas.height / this.workgroupSize.y), 1);\n                    cp.end();\n                }\n                else {\n                    const rp = enc.beginRenderPass({\n                        colorAttachments: [{\n                                view: p.textures[writeIdx].createView(),\n                                loadOp: \"clear\",\n                                storeOp: \"store\",\n                                clearValue: [0, 0, 0, 1]\n                            }],\n                        timestampWrites: tw\n                    });\n                    rp.setPipeline(p.pipelines[0]);\n                    rp.setBindGroup(0, bg);\n                    rp.draw(3);\n                    rp.end();\n                }\n            });\n            let mtw;\n            if (timer) {\n                const idx = timer.allocateIndices();\n                if (idx) {\n                    mtw = {\n                        querySet: timer.querySet,\n                        beginningOfPassWriteIndex: idx.start,\n                        endOfPassWriteIndex: idx.end\n                    };\n                    passTimings.push({ name: \"main\", ...idx });\n                }\n            }\n            const mp = enc.beginRenderPass({\n                colorAttachments: [{\n                        view: this.context.getCurrentTexture().createView(),\n                        loadOp: \"clear\",\n                        storeOp: \"store\",\n                        clearValue: [0, 0, 0, 1]\n                    }],\n                timestampWrites: mtw\n            });\n            mp.setPipeline(this.mainPipeline);\n            mp.setBindGroup(0, this.createBindGroup(this.passes.length, writeIdx));\n            mp.draw(3);\n            mp.end();\n            this.device.queue.submit([enc.finish()]);\n            if (timer)\n                timer.resolve(passTimings);\n            this.frameCounter++;\n            requestAnimationFrame(frame);\n        };\n        requestAnimationFrame(frame);\n        return this;\n    }\n}\nexports.TinyShade = TinyShade;\n\n\n//# sourceURL=webpack://tinyshade/./build/TinyShade.js?");

/***/ }),

/***/ "./build/UniformLayout.js":
/*!********************************!*\
  !*** ./build/UniformLayout.js ***!
  \********************************/
/***/ ((__unused_webpack_module, exports) => {

eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.UniformLayout = void 0;\n/**\n * Manages uniform buffer layout and data for WebGPU shaders.\n *\n * Handles the organization, alignment, and serialization of uniform values\n * according to WGSL specifications. Automatically manages buffer size,\n * proper alignment (including the 16-byte requirement for WebGPU uniform buffers),\n * and provides real-time updates for time-based and function-driven uniforms.\n *\n * @example\n * ```typescript\n * const layout = new UniformLayout([800, 600]);\n * layout.addUniform(\"color\", [1.0, 0.0, 0.0, 1.0]);\n * layout.addUniform(\"speed\", (time) => Math.sin(time));\n * layout.update(performance.now() / 1000);\n * const buffer = layout.float32Array;\n * ```\n */\nclass UniformLayout {\n    entries = [];\n    size = 0;\n    _cache = null;\n    frameCount = 0;\n    currentTime = 0;\n    constructor(initialResolution) {\n        // We initialize with standard global uniforms\n        this.addUniform({ name: \"resolution\", value: initialResolution });\n        this.addUniform({ name: \"time\", value: 0 });\n    }\n    /**\n     * Adds a uniform to the layout with proper WGSL alignment.\n     * @param options - The uniform configuration\n     * @param options.name - The name of the uniform\n     * @param options.value - The value of the uniform\n     * @returns This instance for method chaining\n     */\n    addUniform({ name, value }) {\n        const { type, size, align } = this.inferType(value);\n        // Standard WGSL alignment: offset must be a multiple of 'align'\n        const offset = Math.ceil(this.size / align) * align;\n        this.entries.push({ name, type, size, align, offset, value });\n        this.size = offset + size;\n        this._cache = null; // Reset cache so it grows to fit new size\n        return this;\n    }\n    // This is the critical fix for your animation issue\n    /**\n     * Updates the uniform layout with the current time and increments the frame counter.\n     * @param time - The current time value to update the uniform layout with.\n     */\n    update(time) {\n        this.currentTime = time;\n        this.frameCount++;\n    }\n    /**\n     * Gets the byte size of the uniform layout, rounded up to the nearest multiple of 16.\n     *\n     * @remarks\n     * WebGPU requires uniform buffers to be aligned to 16-byte boundaries.\n     *\n     * @returns The size in bytes, guaranteed to be a multiple of 16.\n     */\n    get byteSize() {\n        // Uniform buffers must be multiples of 16 bytes in WebGPU\n        return Math.ceil(this.size / 16) * 16;\n    }\n    /**\n     * Generates a WGSL struct definition string for the uniform layout.\n     *\n     * @returns {string} A WGSL struct named \"Uniforms\" containing all entries\n     * with their respective names and types, formatted as a valid WGSL struct declaration.\n     *\n     * @example\n     * // Returns: \"struct Uniforms {\\n  position: vec3,\\n  color: vec4,\\n};\"\n     * const structDef = uniformLayout.wgslStruct;\n     */\n    get wgslStruct() {\n        return `struct Uniforms {\\n${this.entries.map(e => `  ${e.name}: ${e.type},`).join(\"\\n\")}\\n};`;\n    }\n    /**\n     * Gets a Float32Array representation of the uniform layout data.\n     *\n     * Lazily initializes and caches a Float32Array buffer sized to accommodate all uniform entries.\n     * Iterates through each entry, resolving its value (from time, a function, or a static value),\n     * and writes the resolved value(s) into the appropriate offset in the cache.\n     *\n     * @returns {Float32Array} The cached Float32Array containing all uniform values in binary format.\n     */\n    get float32Array() {\n        if (!this._cache)\n            this._cache = new Float32Array(this.byteSize / 4);\n        for (const e of this.entries) {\n            let val;\n            // Determine the value based on the entry name or function\n            if (e.name === \"time\") {\n                val = this.currentTime;\n            }\n            else if (typeof e.value === \"function\") {\n                val = e.value(this.currentTime, this.frameCount);\n            }\n            else {\n                val = e.value;\n            }\n            const startIndex = e.offset / 4;\n            if (typeof val === \"number\") {\n                this._cache[startIndex] = val;\n            }\n            else {\n                for (let i = 0; i < val.length; i++) {\n                    this._cache[startIndex + i] = val[i];\n                }\n            }\n        }\n        return this._cache;\n    }\n    /**\n     * Infers the WGSL type and memory layout information for a uniform value.\n     * @param value - The uniform value to infer the type for. Can be a number, array of numbers, or a function that returns one of these.\n     * @returns An object containing the WGSL type name, size in bytes, and alignment requirement in bytes.\n     * @throws {Error} If the uniform array length is not 2, 3, or 4.\n     */\n    inferType(value) {\n        const sample = typeof value === \"function\" ? value(0, 0) : value;\n        if (typeof sample === \"number\")\n            return { type: \"f32\", size: 4, align: 4 };\n        const len = sample.length;\n        switch (len) {\n            case 2: return { type: \"vec2f\", size: 8, align: 8 };\n            case 3: return { type: \"vec3f\", size: 12, align: 16 }; // Note: vec3 aligns to 16\n            case 4: return { type: \"vec4f\", size: 16, align: 16 };\n            default: throw new Error(`Uniform array length ${len} not supported.`);\n        }\n    }\n}\nexports.UniformLayout = UniformLayout;\n\n\n//# sourceURL=webpack://tinyshade/./build/UniformLayout.js?");

/***/ }),

/***/ "./build/example/example7.js":
/*!***********************************!*\
  !*** ./build/example/example7.js ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nconst GPUSynth_1 = __webpack_require__(/*! ../plugins/GPUSynth */ \"./build/plugins/GPUSynth.js\");\nconst TinyShade_1 = __webpack_require__(/*! ../TinyShade */ \"./build/TinyShade.js\");\nconst start = async () => {\n    const app = await TinyShade_1.TinyShade.create(\"canvas\");\n    const audio = new GPUSynth_1.GPUSynth(app.device, GPUSynth_1.SWEET_DREAMS_WGSL);\n    (await app\n        .addAudio(audio)\n        .setUniforms()\n        .addCommon(/*wgsl*/ `\r\n            const MAT_GROUND = 1.0;\r\n            const MAT_TORUS = 2.0;\r\n            const MAT_SPHERE = 3.0;\r\n\r\n            fn rot(a: f32) -> mat2x2f {\r\n                let s = sin(a); let c = cos(a);\r\n                return mat2x2f(c, -s, s, c);\r\n            }\r\n\r\n            fn sdfScene(p: vec3f) -> vec2f {\r\n                let ground = p.y + 1.5;\r\n                \r\n                // FIXED: No LHS swizzling. Reconstruct vector for rotation.\r\n                let rotatedXZ = rot(u.time * 0.5) * p.xz;\r\n                let tp = vec3f(rotatedXZ.x, p.y, rotatedXZ.y);\r\n                \r\n                let q = vec2f(length(tp.xz) - 4.5, tp.y);\r\n                let torus = length(q) - 0.2;\r\n                \r\n                let sPos = vec3f(0.0, 0.5 + sin(u.time * 1.5) * 0.5, 0.0);\r\n                let sphere = length(p - sPos) - (1.2 + sin(u.time * 4.0) * 0.05);\r\n                \r\n                var res = vec2f(ground, MAT_GROUND);\r\n                if (torus < res.x) { res = vec2f(torus, MAT_TORUS); }\r\n                if (sphere < res.x) { res = vec2f(sphere, MAT_SPHERE); }\r\n                return res;\r\n            }\r\n\r\n            // High-quality Sky with a distinct \"Sun Dot\" as the main source\r\n            fn getSky(rd: vec3f, lightDir: vec3f) -> vec3f {\r\n                let sun = max(dot(rd, lightDir), 0.0);\r\n                // Deep atmosphere gradient\r\n                var col = mix(vec3f(0.005, 0.01, 0.03), vec3f(0.1, 0.25, 0.5), pow(1.0 - max(rd.y, 0.0), 3.0));\r\n                // Sun Disk (Intense core)\r\n                col += vec3f(1.0, 0.9, 0.7) * pow(sun, 1024.0) * 20.0; \r\n                // Sun Halo (Soft glow)\r\n                col += vec3f(0.8, 0.4, 0.2) * pow(sun, 32.0) * 0.6; \r\n                return col;\r\n            }\r\n\r\n            // Soft shadows for depth\r\n            fn getShadow(ro: vec3f, rd: vec3f) -> f32 {\r\n                var res = 1.0;\r\n                var t = 0.02;\r\n                for(var i=0; i<32; i++) {\r\n                    let h = sdfScene(ro + rd * t).x;\r\n                    res = min(res, 12.0 * h / t); // 12.0 is the softness factor\r\n                    t += clamp(h, 0.01, 0.2);\r\n                    if(res < 0.001 || t > 15.0) { break; }\r\n                }\r\n                return clamp(res, 0.0, 1.0);\r\n            }\r\n        `)\n        .addPass(\"pass0\", /*wgsl*/ `\r\n            @fragment fn main(in: VSOut) -> @location(0) vec4f {\r\n                let uv = vec2f(in.uv.x * 2.0 - 1.0, (1.0 - in.uv.y) * 2.0 - 1.0);\r\n                let p_uv = vec2f(uv.x * u.resolution.z, uv.y);\r\n\r\n                // Camera Logic\r\n                let camTime = u.time * 0.2;\r\n                let ro = vec3f(cos(camTime) * 12.0, 4.0, sin(camTime) * 12.0);\r\n                let tar = vec3f(0.0, 0.0, 0.0);\r\n                let ww = normalize(tar - ro);\r\n                let uu = normalize(cross(ww, vec3f(0.0, 1.0, 0.0)));\r\n                let vv = normalize(cross(uu, ww));\r\n                let rd = normalize(p_uv.x * uu + p_uv.y * vv + 1.8 * ww);\r\n                \r\n                // Main Sun Direction\r\n                let lightDir = normalize(vec3f(0.7, 0.7, 0.3)); \r\n                \r\n                var t = 0.0; var m = -1.0;\r\n                for(var i=0; i<100; i++) {\r\n                    let h = sdfScene(ro + rd * t);\r\n                    if(h.x < 0.001 || t > 50.0) { break; }\r\n                    t += h.x; m = h.y;\r\n                }\r\n\r\n                var col: vec3f;\r\n                if(t > 50.0) {\r\n                    col = getSky(rd, lightDir);\r\n                } else {\r\n                    let p = ro + rd * t;\r\n                    let e = vec2f(0.001, 0.0);\r\n                    let n = normalize(vec3f(\r\n                        sdfScene(p + e.xyy).x - sdfScene(p - e.xyy).x,\r\n                        sdfScene(p + e.yxy).x - sdfScene(p - e.yxy).x,\r\n                        sdfScene(p + e.yyx).x - sdfScene(p - e.yyx).x\r\n                    ));\r\n                    \r\n                    let shadow = getShadow(p, lightDir);\r\n                    let diff = max(dot(n, lightDir), 0.0) * shadow;\r\n                    let amb = 0.05 * (n.y * 0.5 + 0.5); // Ambient sky light\r\n                    \r\n                    var baseCol = vec3f(0.5);\r\n                    if (m == MAT_GROUND) {\r\n                         let grid = smoothstep(-0.1, 0.1, sin(p.x * 1.5) * sin(p.z * 1.5));\r\n                         baseCol = mix(vec3f(0.01), vec3f(0.04), grid);\r\n                    } else if (m == MAT_TORUS) { \r\n                        baseCol = vec3f(0.9, 0.05, 0.1); \r\n                    } else if (m == MAT_SPHERE) { \r\n                        baseCol = vec3f(0.05, 0.5, 1.0); \r\n                    }\r\n\r\n                    // Specular Highlight\r\n                    let reflectDir = reflect(rd, n);\r\n                    let spec = pow(max(dot(reflectDir, lightDir), 0.0), 128.0) * shadow;\r\n                    \r\n                    // Fresnel rim lighting\r\n                    let fre = pow(clamp(1.0 + dot(rd, n), 0.0, 1.0), 5.0);\r\n                    \r\n                    col = baseCol * (diff + amb) + spec + (fre * 0.5 * getSky(reflectDir, lightDir));\r\n                }\r\n\r\n                // Smooth exponential fog\r\n                col = mix(col, getSky(rd, lightDir), 1.0 - exp(-0.0001 * t * t * t));\r\n                return vec4f(col, 1.0);\r\n            }\r\n        `)\n        .main(/*wgsl*/ `\r\n            @fragment fn main(in: VSOut) -> @location(0) vec4f {\r\n                let scene = textureSample(pass0, samp, in.uv).rgb;\r\n                \r\n                // Filmic Bloom: Only glow the brightest highlights\r\n                var bloom = vec3f(0.0);\r\n                let samples = 8;\r\n                for(var i=0; i<samples; i++) {\r\n                    let angle = f32(i) * 6.28 / f32(samples);\r\n                    let off = vec2f(cos(angle), sin(angle)) * 0.005;\r\n                    bloom += max(textureSample(pass0, samp, in.uv + off).rgb - 0.7, vec3f(0.0));\r\n                }\r\n                bloom /= f32(samples);\r\n\r\n                // Chromatic Aberration\r\n                let offset = length(in.uv - 0.5) * 0.004;\r\n                let r = textureSample(pass0, samp, in.uv + vec2f(offset, 0.0)).r;\r\n                let g = scene.g;\r\n                let b = textureSample(pass0, samp, in.uv - vec2f(offset, 0.0)).b;\r\n                \r\n                let fin = vec3f(r, g, b) + bloom * 2.0;\r\n                \r\n                // ACES-ish Tonemapping and Gamma\r\n                let mapped = fin / (fin + 1.0);\r\n                return vec4f(pow(mapped, vec3f(0.4545)), 1.0);\r\n            }\r\n        `));\n    const startButton = document.querySelector(\"button\");\n    startButton.addEventListener('click', () => {\n        startButton.classList.add('d-none');\n        app.run();\n    }, { once: true });\n};\nstart();\n\n\n//# sourceURL=webpack://tinyshade/./build/example/example7.js?");

/***/ }),

/***/ "./build/plugins/GPUSynth.js":
/*!***********************************!*\
  !*** ./build/plugins/GPUSynth.js ***!
  \***********************************/
/***/ ((__unused_webpack_module, exports) => {

eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.SWEET_DREAMS_WGSL = exports.GPUSynth = void 0;\n/**\n * GPU-accelerated audio synthesizer that uses WebGPU compute shaders to generate audio samples.\n *\n * Generates audio in chunks by dispatching compute work to the GPU, then reads back the results\n * and schedules them for playback through the Web Audio API.\n *\n * GPUSynth is originally written by Crush for SYTYCD 2025\n *\n * @example\n * ```typescript\n * const device = await navigator.gpu.requestAdapter().requestDevice();\n * const wgslShader = `@compute @workgroup_size(64) fn main(...) { ... }`;\n * const synth = new GPUSynth(device, wgslShader);\n * await synth.play();\n * ```\n */\nclass GPUSynth {\n    ctx;\n    device;\n    pipeline;\n    storageBuffer;\n    readBuffer;\n    uniformBuffer;\n    bindGroup;\n    sampleRate;\n    bufferSamples = 16384;\n    absoluteSampleCount = 0;\n    nextScheduleTime = 0;\n    /**\n     * Initializes a TinyAudio instance with GPU compute capabilities for audio processing.\n     *\n     * @param device - The GPU device used for creating buffers and compute pipelines\n     * @param wgslSource - The WGSL shader source code for the compute pipeline\n     *\n     * @remarks\n     * This constructor sets up:\n     * - An AudioContext for audio output with the system's sample rate\n     * - GPU storage buffers for audio sample data and readback operations\n     * - A uniform buffer for passing parameters to the compute shader\n     * - A compute pipeline from the provided WGSL source\n     * - A bind group linking the uniform and storage buffers to the pipeline\n     *\n     * The storage buffer size is calculated based on `bufferSamples` property (4 bytes per sample).\n     */\n    constructor(device, wgslSource) {\n        this.device = device;\n        this.ctx = new AudioContext();\n        this.sampleRate = this.ctx.sampleRate;\n        const byteSize = this.bufferSamples * 4;\n        this.storageBuffer = device.createBuffer({\n            size: byteSize,\n            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC\n        });\n        this.readBuffer = device.createBuffer({\n            size: byteSize,\n            usage: GPUBufferUsage.COPY_DST | GPUBufferUsage.MAP_READ\n        });\n        this.uniformBuffer = device.createBuffer({\n            size: 16,\n            usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST\n        });\n        const shaderModule = device.createShaderModule({ code: wgslSource });\n        this.pipeline = device.createComputePipeline({\n            layout: 'auto',\n            compute: { module: shaderModule, entryPoint: 'main' }\n        });\n        this.bindGroup = device.createBindGroup({\n            layout: this.pipeline.getBindGroupLayout(0),\n            entries: [\n                { binding: 0, resource: { buffer: this.uniformBuffer } },\n                { binding: 1, resource: { buffer: this.storageBuffer } }\n            ]\n        });\n    }\n    isPlaying = false;\n    /**\n     * Gets the current playback time of the audio context.\n     * @returns The current time in seconds.\n     */\n    getTime() {\n        return this.ctx.currentTime;\n    }\n    async generateChunk(startTime, channel) {\n        const uniformData = new Float32Array([startTime, this.sampleRate, channel, 0]);\n        this.device.queue.writeBuffer(this.uniformBuffer, 0, uniformData);\n        const encoder = this.device.createCommandEncoder();\n        const pass = encoder.beginComputePass();\n        pass.setPipeline(this.pipeline);\n        pass.setBindGroup(0, this.bindGroup);\n        pass.dispatchWorkgroups(Math.ceil(this.bufferSamples / 64));\n        pass.end();\n        encoder.copyBufferToBuffer(this.storageBuffer, 0, this.readBuffer, 0, this.readBuffer.size);\n        this.device.queue.submit([encoder.finish()]);\n        await this.readBuffer.mapAsync(GPUMapMode.READ);\n        const audioData = new Float32Array(this.readBuffer.getMappedRange()).slice();\n        this.readBuffer.unmap();\n        return audioData;\n    }\n    /**\n     * Plays audio using the Web Audio API scheduler pattern.\n     *\n     * Resumes the audio context if it's suspended, then schedules audio buffer chunks\n     * to be played with a 0.5 second lookahead buffer. Each chunk is generated for both\n     * left and right channels and queued for playback.\n     *\n     * @param cb - Optional callback function to execute immediately after scheduling begins\n     * @returns A promise that resolves after the scheduler is initiated\n     *\n     * @remarks\n     * - The scheduler runs on a 100ms interval to maintain the audio playback queue\n     * - Audio chunks are scheduled with a minimum 0.1 second offset from current time\n     * - The absolute sample count is incremented to track the total samples processed\n     *\n     * @example\n     * ```typescript\n     * await audioPlayer.play(() => console.log('Playback started'));\n     * ```\n     */\n    async play(cb) {\n        if (this.ctx.state === 'suspended')\n            await this.ctx.resume();\n        this.isPlaying = true;\n        this.nextScheduleTime = this.ctx.currentTime + 0.1;\n        const scheduler = async () => {\n            if (!this.ctx)\n                return;\n            while (this.nextScheduleTime < this.ctx.currentTime + 0.5) {\n                const startS = this.absoluteSampleCount / this.sampleRate;\n                const left = await this.generateChunk(startS, 0);\n                const right = await this.generateChunk(startS, 1);\n                const audioBuf = this.ctx.createBuffer(2, this.bufferSamples, this.sampleRate);\n                audioBuf.copyToChannel(left, 0);\n                audioBuf.copyToChannel(right, 1);\n                const source = this.ctx.createBufferSource();\n                source.buffer = audioBuf;\n                source.connect(this.ctx.destination);\n                source.start(this.nextScheduleTime);\n                this.nextScheduleTime += this.bufferSamples / this.sampleRate;\n                this.absoluteSampleCount += this.bufferSamples;\n            }\n            setTimeout(scheduler, 100);\n        };\n        scheduler();\n        if (cb)\n            cb();\n    }\n}\nexports.GPUSynth = GPUSynth;\n/**\n * WGSL compute shader for synthesizing \"Sweet Dreams\" audio.\n *\n * Generates a polyphonic synthesizer with 16 simultaneous voices playing a predefined\n * melody pattern, combined with a kick drum pulse. The shader uses triangle wave oscillators\n * with stereo phase shifting and ADSR envelope modulation.\n *\n * @remarks\n * - Processes audio samples at the specified sample rate\n * - Uses a 16-note repeating melody with BPS (beats per second) timing at 2.1 BPS\n * - Each voice has an independent ADSR envelope starting at different times\n * - Applies pitch shifting based on the second half of a 32-beat cycle\n * - Includes stereo channel separation via phase modulation\n * - Adds a percussive kick drum with its own envelope\n *\n * @group 0 @binding 0 - AudioUniforms containing bufferTime, sampleRate, channel, and padding\n * @group 0 @binding 1 - Read-write storage buffer for output audio samples\n *\n * @returns void - Writes processed audio samples to the output buffer\n *\n * @example\n * // Used in a compute pipeline to generate audio in real-time\n * // Output values are clamped to [-1.0, 1.0] range for valid audio\n */\nexports.SWEET_DREAMS_WGSL = `\r\n\r\nstruct AudioUniforms {\r\n    bufferTime: f32,\r\n    sampleRate: f32,\r\n    channel: f32,\r\n    _pad: f32,\r\n};\r\n\r\n@group(0) @binding(0) var<uniform> u: AudioUniforms;\r\n@group(0) @binding(1) var<storage, read_write> output: array<f32>;\r\n\r\nconst PI: f32 = 3.14159265359;\r\nconst BPS: f32 = 2.1;\r\n\r\nfn noteToFreq(n: f32) -> f32 {\r\n    return pow(2.0, (n - 49.0) / 12.0) * 440.0;\r\n}\r\n\r\nfn adsr(t_abs: f32, env: vec4f, start: f32, duration: f32) -> f32 {\r\n    let t = t_abs - start;\r\n    let sustain = env.z;\r\n    let t1 = env.x;\r\n    let t2 = t1 + env.y;\r\n    let t3 = max(t2, duration);\r\n    let t4 = t3 + env.w;\r\n\r\n    if (t < 0.0 || t > t4) { return 0.0; }\r\n    if (t <= t1) { return smoothstep(0.0, t1, t); }\r\n    if (t <= t2) { return sustain + smoothstep(t2, t1, t) * (1.0 - sustain); }\r\n    if (t <= t3) { return sustain; }\r\n    return sustain * smoothstep(t4, t3, t);\r\n}\r\n\r\nfn tri(t: f32, x: f32) -> f32 {\r\n    return abs(1.0 - ((2.0 * t * x) % 2.0)) * 2.0 - 1.0;\r\n}\r\n\r\nfn synth(t: f32, f: f32) -> f32 {\r\n    var time = t;\r\n    // Stereo phase shift based on channel\r\n    time += select(0.2, 0.6, u.channel > 0.5) * sin(t * 2.0) / f;\r\n    return 0.3 * tri(time, f / 2.0) + 0.2 * tri(time, f / 4.0);\r\n}\r\n\r\n@compute @workgroup_size(64)\r\nfn main(@builtin(global_invocation_id) id: vec3u) {\r\n    let idx = id.x;\r\n    if (idx >= arrayLength(&output)) { return; }\r\n\r\n    let t = u.bufferTime + f32(idx) / u.sampleRate;\r\n    let m = (t * BPS * 2.0) % 16.0;\r\n    \r\n    var notes = array<f32, 16>(24., 24., 36., 48., 39., 51., 36., 48., 32., 32., 44., 48., 31., 31., 46., 48.);\r\n    var sound: f32 = 0.0;\r\n\r\n    for (var i: i32 = 0; i < 16; i = i + 1) {\r\n        let is_second_half = ((t * BPS * 2.0) % 32.0) > 16.0;\r\n        let pitch_factor = select(2.0, 1.0, is_second_half);\r\n        \r\n        sound += synth(t, pitch_factor * noteToFreq(notes[i])) * adsr(m, vec4f(0.1, 0.2, 0.7, 0.8), f32(i), 0.6);\r\n    }\r\n\r\n    // Add a simple kick drum pulse\r\n    let beat_t = (t * BPS) % 2.0;\r\n    let kick = tri(beat_t, 60.0 * smoothstep(0.4, 0.0, beat_t)) * adsr(beat_t, vec4f(0.01, 0.1, 0.0, 0.2), 0.0, 0.2);\r\n\r\n    output[idx] = clamp((sound * 0.4) + (kick * 0.5), -1.0, 1.0);\r\n}`;\n\n\n//# sourceURL=webpack://tinyshade/./build/plugins/GPUSynth.js?");

/***/ })

/******/ 	});
/************************************************************************/
/******/ 	// The module cache
/******/ 	var __webpack_module_cache__ = {};
/******/ 	
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/ 		// Check if module is in cache
/******/ 		var cachedModule = __webpack_module_cache__[moduleId];
/******/ 		if (cachedModule !== undefined) {
/******/ 			return cachedModule.exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = __webpack_module_cache__[moduleId] = {
/******/ 			// no module.id needed
/******/ 			// no module.loaded needed
/******/ 			exports: {}
/******/ 		};
/******/ 	
/******/ 		// Execute the module function
/******/ 		__webpack_modules__[moduleId](module, module.exports, __webpack_require__);
/******/ 	
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/ 	
/************************************************************************/
/******/ 	
/******/ 	// startup
/******/ 	// Load entry module and return exports
/******/ 	// This entry module can't be inlined because the eval devtool is used.
/******/ 	var __webpack_exports__ = __webpack_require__("./build/example/example7.js");
/******/ 	
/******/ })()
;